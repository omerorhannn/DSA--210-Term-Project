{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-header",
   "metadata": {},
   "source": [
    "# The Impact of Sleep Quality on Daily Cognitive Performance\n",
    "## DSA 210 Project Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(\"Dsa210_Project_Data.csv\")\n",
    "    print(\"Data loaded successfully.\")\n",
    "    print(f\"Shape before cleaning: {df.shape}\")\n",
    "    \n",
    "    # Data cleaning (dropping missing values)\n",
    "    df = df.dropna()\n",
    "    print(f\"Shape after cleaning: {df.shape}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    display(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please check the file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda-header",
   "metadata": {},
   "source": [
    "# Step 1: Exploratory Data Analysis (EDA)\n",
    "### Addressing feedback: \"The visualization is very limited\"\n",
    "This section includes Correlation Heatmap and Pairplots to better understand the data before statistical testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 1: EXPLORATORY DATA ANALYSIS (EDA)\n",
    "# ==========================================\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Correlation Matrix (Heatmap) ---\n",
    "plt.figure(figsize=(12, 10))\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix: Sleep Features vs. Cognitive Scores\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# --- 2. Pairplot Analysis ---\n",
    "selected_features = ['SleepDuration', 'SleepEfficiency', 'WASO', 'ReactionTime', 'AttentionScore']\n",
    "existing_features = [col for col in selected_features if col in df.columns]\n",
    "\n",
    "if existing_features:\n",
    "    sns.pairplot(df[existing_features], diag_kind='kde', corner=True)\n",
    "    plt.suptitle(\"Pairplot of Key Sleep & Cognitive Metrics\", y=1.02, fontsize=16)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Warning: Selected features for pairplot not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stats-header",
   "metadata": {},
   "source": [
    "# Step 2: Statistical Hypothesis Testing\n",
    "Here we perform Pearson Correlation tests to validate our hypotheses regarding sleep metrics and cognitive scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hypothesis-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Sleep Duration vs. Reaction Time\n",
    "if 'SleepDuration' in df.columns and 'ReactionTime' in df.columns:\n",
    "    r_duration, p_duration = stats.pearsonr(df['SleepDuration'], df['ReactionTime'])\n",
    "    print(f\"\\n1. Hypothesis: Sleep Duration vs. Reaction Time\")\n",
    "    print(f\"   Pearson Correlation (r): {r_duration:.3f}\")\n",
    "    print(f\"   P-value: {p_duration:.5f}\")\n",
    "    if p_duration < 0.05:\n",
    "        print(\"   Result: Reject Null Hypothesis. Significant relationship found.\")\n",
    "    else:\n",
    "        print(\"   Result: Fail to reject Null Hypothesis. No significant relationship.\")\n",
    "\n",
    "# Test 2: Deep Sleep vs. Memory Recall\n",
    "if 'DeepSleep' in df.columns and 'MemoryRecall' in df.columns:\n",
    "    r_deep, p_deep = stats.pearsonr(df['DeepSleep'], df['MemoryRecall'])\n",
    "    print(f\"\\n2. Hypothesis: Deep Sleep vs. Memory Recall\")\n",
    "    print(f\"   Pearson Correlation (r): {r_deep:.3f}\")\n",
    "    print(f\"   P-value: {p_deep:.5f}\")\n",
    "    if p_deep < 0.05:\n",
    "        print(\"   Result: Reject Null Hypothesis. Significant relationship found.\")\n",
    "    else:\n",
    "        print(\"   Result: Fail to reject Null Hypothesis. No significant relationship.\")\n",
    "\n",
    "# Test 3: WASO (Wake After Sleep Onset) vs. Attention Score\n",
    "if 'WASO' in df.columns and 'AttentionScore' in df.columns:\n",
    "    r_attention, p_attention = stats.pearsonr(df['WASO'], df['AttentionScore'])\n",
    "    print(f\"\\n3. Hypothesis: WASO vs. Attention Score\")\n",
    "    print(f\"   Pearson Correlation (r): {r_attention:.3f}\")\n",
    "    print(f\"   P-value: {p_attention:.5f}\") \n",
    "\n",
    "    if p_attention < 0.05:\n",
    "        print(\"   Result: Reject Null Hypothesis. Significant relationship found.\")\n",
    "    else:\n",
    "        print(\"   Result: Fail to reject Null Hypothesis. No significant relationship.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ml-header",
   "metadata": {},
   "source": [
    "# Step 3: Machine Learning Analysis\n",
    "### Addressing feedback: \"Technical analysis seems limited\"\n",
    "This section implements a Random Forest Regressor to predict Reaction Time based on sleep metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ml-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 3: MACHINE LEARNING ANALYSIS\n",
    "# ==========================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# --- 1. Feature Selection ---\n",
    "target_col = 'ReactionTime'\n",
    "feature_cols = ['SleepDuration', 'SleepEfficiency', 'DeepSleep', 'REM', 'WASO']\n",
    "\n",
    "available_features = [col for col in feature_cols if col in df.columns]\n",
    "\n",
    "if target_col in df.columns and available_features:\n",
    "    X = df[available_features]\n",
    "    y = df[target_col]\n",
    "\n",
    "    # --- 2. Train-Test Split ---\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --- 3. Model Training (Random Forest) ---\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # --- 4. Prediction & Evaluation ---\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Model Performance: Random Forest Regressor\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Target Variable : {target_col}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"RÂ² Score        : {r2:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # --- 5. Feature Importance ---\n",
    "    feature_importances = pd.Series(rf_model.feature_importances_, index=available_features)\n",
    "    print(\"\\nFeature Importance (Top Predictors):\")\n",
    "    print(feature_importances.sort_values(ascending=False))\n",
    "\n",
    "    # --- 6. Visualization: Actual vs. Predicted ---\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.scatter(y_test, y_pred, color='#2c3e50', alpha=0.7, s=100, label='Test Data Points')\n",
    "    \n",
    "    min_val = min(y.min(), y_pred.min())\n",
    "    max_val = max(y.max(), y_pred.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction Line')\n",
    "    \n",
    "    plt.xlabel(f\"Actual {target_col}\", fontsize=12)\n",
    "    plt.ylabel(f\"Predicted {target_col}\", fontsize=12)\n",
    "    plt.title(f\"Model Evaluation: Actual vs. Predicted {target_col}\", fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Target '{target_col}' or features not found in dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
